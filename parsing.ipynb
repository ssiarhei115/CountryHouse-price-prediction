{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(executable_path=r'/usr/bin/chromedriver')\n",
    "options = webdriver.ChromeOptions()\n",
    "#options.add_argument('--headless') #It allows users to run automated scripts in headless mode, meaning that the browser window wouldn’t be visible. \n",
    "#options.add_argument('--no-sandbox')\n",
    "#options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "url = 'https://realt.by/belarus/sale/dachi/?page=1'#\"https://realt.by/sale/dachi/?page=1\"\n",
    "headers = ({'User-Agent':'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:124.0) Gecko/20100101 Firefox/124.0', 'Accept-Language':'en-US, en;q=0.5'})\n",
    "driver.get(url);\n",
    "time.sleep(5)\n",
    "\n",
    "#try:\n",
    "#    cookie_ok_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, \"cookie-banner__container\"))) # 'cookie-banner__container'\n",
    "#    cookie_ok_button.accept()\n",
    "#except TimeoutException:\n",
    "#    print(\"no cookie popup\")\n",
    "\n",
    "SCROLL_PAUSE_TIME = random.randint(5,8)\n",
    "\n",
    "full_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "height = 0 \n",
    "cnt = 0\n",
    "res = []\n",
    "\n",
    "while True:\n",
    "    res = []\n",
    "    rand = random.randint(5,8)\n",
    "    print(cnt)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    r = soup.find_all(\"div\", class_=\"sm:w-full w-full p-1.5 sm:p-2.5\")\n",
    "    for e in r:\n",
    "        add = e.find('a')['href']\n",
    "        if add not in res:\n",
    "            res.append(add)\n",
    "    \n",
    "    with open('data/pars_res.txt', 'a') as f:\n",
    "        f.write(','.join(res)+',') \n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = height + driver.execute_script(\"return document.body.clientHeight\")\n",
    "    try:\n",
    "        if new_height >= full_height and driver.find_element(By.LINK_TEXT, 'Далее'):\n",
    "            #print('next is')\n",
    "            driver.find_element(By.LINK_TEXT, 'Далее').click()\n",
    "            time.sleep(rand)\n",
    "            full_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            new_height = 0\n",
    "            cnt +=1\n",
    "    except:\n",
    "        print('last')\n",
    "        break    \n",
    "    height = new_height \n",
    "    driver.execute_script(f\"window.scrollTo(0, {height});\")\n",
    "    time.sleep(rand)\n",
    "    \n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/brest-region/sale-dachi/object/3227872/',\n",
       " '/brest-region/sale-dachi/object/3226705/',\n",
       " '/brest-region/sale-dachi/object/3292562/',\n",
       " '/brest-region/sale-dachi/object/3273030/',\n",
       " '/brest-region/sale-dachi/object/3290219/']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/pars_res.txt', 'r') as f:\n",
    "    res = f.readlines()\n",
    "\n",
    "res = res[0].split(',')\n",
    "\n",
    "res[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "no_price = []\n",
    "\n",
    "def get_item(url):\n",
    "    url = 'https://realt.by' + url\n",
    "    page = requests.get(url)\n",
    "    time.sleep(3)\n",
    "    if page.status_code != 200:\n",
    "        print(url, page.status_code)\n",
    "        return 0\n",
    "    \n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    rdict = {'index': int(url.split('/')[-2])}\n",
    "    r = soup.find_all('section', class_='bg-white flex flex-wrap md:p-6 my-4 rounded-md') \n",
    "    \n",
    "    sections = {'Параметры объекта':10, 'Инфраструктура':10, 'Местоположение':10}\n",
    "    for i,k in enumerate(r):\n",
    "        if k.find('h3').text in sections:\n",
    "            sections[k.find('h3').text] = i \n",
    "\n",
    "    try:\n",
    "        res_1 = r[sections['Параметры объекта']].find(\"ul\", class_=\"w-full -my-1\").find_all('li', class_='relative py-1')\n",
    "        for li in res_1:\n",
    "            key = li.find('span', class_='text-basic sm:flex-shrink-0 mr-2')\n",
    "            value = li.find('p').getText()\n",
    "            if key.text not in rdict:\n",
    "                rdict[key.text] = [value.split()]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        res_2 = r[sections['Инфраструктура']].find_all('p')\n",
    "        for p in res_2:\n",
    "            key = p.getText()\n",
    "            rdict[key] = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        res_3 = r[sections['Местоположение']].find('ul', class_='w-full mb-0.5 -my-1')\n",
    "        for li in res_3:\n",
    "            key = li.find('span', class_='text-basic sm:flex-shrink-0 mr-2')\n",
    "            if li.find('a'):\n",
    "                value = li.find('a').contents[0]\n",
    "            elif li.find('p'):\n",
    "                value = li.find('p').getText()\n",
    "            rdict[key.text] = [value.split()]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        res_4 = soup.find('div', class_='bg-white flex flex-wrap md:p-6 rounded-md').find('h2') \n",
    "        rdict['Цена'] = res_4.text.strip()\n",
    "    except:\n",
    "        print(url,'no price')\n",
    "        no_price.append(url)\n",
    "        pass\n",
    "    return pd.DataFrame(rdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(set(res)):\n",
    "    try:\n",
    "        df = pd.concat([df,get_item(i)], axis=0)\n",
    "        df.to_csv('data/country_houses_2.csv')\n",
    "    except:\n",
    "        print(f'exception for {i}')\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
